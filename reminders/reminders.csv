Routine,Title,Message,Event,Status
*,NLP Suite reminders,Several NLP Suite scripts will fire up reminders for the user. You can turn them off once you are familiar with a script. You can always turn any reminder back ON (or OFF for that matter) if you select the reminders dropdown menu at the bottom of each GUI and then select a specific reminder (if reminders are available for that GUI).,Yes,No
*,Input/Output configurations,"Most GUIs in the NLP Suite provide two types of Input/Output (I/O) configurations that specify your selection for your input file or directory (these are MUTUALLY EXCLUSIVE. YOU CAN ONLY HAVE ONE OR THE OTHER BUT NOT BOTH) and output directory:

  Default I/O configuration
 GUI-specific I/O configuration

The Default I/O configuration applies to ALL GUIs in the NLP Suite. This is an ideal option if you work exclusively, or mostly, with the same input file(s) regardless of GUI (i.e., NLP algorithms); you would not need to select these options for every GUI.

If you occasionally need to run a script using a different set of I/O options, setup theGUI-specific I/O configuration. This will not affect your I/O selections for all GUIs and will only apply to a specific GUI if you chose the menu optionGUI-specific I/O configuration.",No,No
NLP,NLP Suite welcome & system requirements,"Welcome to the NLP Suite a package of Python 3 and Java tools designed for text processing and visualization. The Suite requires several FREWARE software components in order to run. You will need to download and install them or some functionality will be lost for some of the scripts (e.g., you cannot do any textual analysis of any kind without Stanford CoreNLP or produce any geographic maps without Google Earth Pro).

   1. JAVA. Several scripts are based on the FREEWARE Java. You can download and install Java at https://www.java.com/en/download

   2. STANFORD CORENLP. The core text analyses of the NLP Suite are based on the FREEWARE Stanford CoreNLP. You can download Stanford CoreNLP at https://stanfordnlp.github.io/CoreNLP/download.html.

   3. GEPHI. The visualization of network graphs requires the installation of the FREEWARE software Gephi. You can download and install Gephi at https://gephi.org/users/download/

   4. GOOGLE EARTH PRO. The visualization of geographic maps requires the installation of the FREEWARE software Google Earth Pro. You can download and install Google Earth Pro at https://www.google.com/earth/versions/#download-pro.

   5. MALLET. MALLET topic modelling requires the installation of the FREEWARE MALLET. You can download and install MALLET at http://mallet.cs.umass.edu/download.php.

   7. SENNA. The FREEWARE SENNA will allow you to extract Subject-Verb-Object from a text. You can download SENNA at https://ronan.collobert.com/senna/download.html.",Yes,No
NLP,NLP Suite architecture & filenames,"The Python scripts in the NLP Suite have filenames that clearly identify the Suite architecture.

The filename suffix designates two different types of files: _main and _util.

_main files are the only ones that you can run in command line independently of others; they may call _util files.

The _main files, with their GUI options, lay out on the screen the widgets of a script for easy Graphical User Interface (GUI).

ALL SCRIPTS SUFFIXED BY _main CAN BE RUN INDIPENDENTLY OF THE NLP SUITE. Thus on command line you can type
Python knowledge_graphs_main.py
and it will fire up the annotator GUI independently of NLP_main.py.

The filename prefix cluster together scripts used for the same purpose. Thus annotator identifies all files dealing with html annotation.",Yes,No
default,Input/Output options,"The two widgets for INPUT FILE and INPUT DIRECTORY are mutually exclusive. You can select one OR the other but not both. Click on either button to make your selection.

To change an already selected option from FILE to DIRECTORY or from DIRECTORY to FILE, simply click on the button you want to select, make your selection, and the I/O configuration will automatically update.",No,No
*,Excel Charts,"The Excel chart to be displayed has hover-over effects (i.e., when you hover the mouse over chart points some information will be displayed).

First, hover-over charts are based on Excel macros. You need to enable macros in Excel to view the chart (read the TIPS file on how to do this).

Second, if the Excel chart has nothing in it or chart titles are not displayed, you need to hover the mouse over the chart area to display the chart properly. That is how hover-over charts work.

Third, if the chart is displayed but the bars of a bar chart, for instance, have the same height, contrary to expectations, click on Data then on Chart to display the chart properly.",Yes,No
*,csv files,"If csv ouput files open displaying weird characters in a Windows OS (e.g., aâ‚¬), most likely the cause is due to non utf-8 compliant input text. Apostrophes and quotes are the typical culprits, but also other punctuation characters.

Please, run the tool to check documents for utf-8 compliance and, if necessary, run the tool for automatic apostrophe and quote conversion from non utf-8 to utf-8.

To learm more on utf-8 compliance, read the TIPS on utf-8 compliance.",Yes,No
whats_in_your_corpus,CoreNLP POS/NER max sentence length,"The CoreNLP POS/NER annotators set a maximum sentence length for processing.

Sentences longer than your selected max length will be cut and some POS/NER tags in those long sentences may be lost.",Yes,No
whats_in_your_corpus,CoreNLP sentence length,"The length of the current sentence exceeds 100 words. The average sentence length in modern English is 20 words.

More to the point, Stanford CoreNLP's performance deteriorates with sentences with more that 70/100 words.

You should run the algorithm that extracts all sentences from a corpus and computes sentence length. This will allow you to either edit the sentence manually or perhaps run the algorithm that will add full stops (.) to sentences without end-of-sentence markers (too many sentences of this kind, one after the other, can create unduly long sentences).

On Stanford CoreNLP and memory and performance issues and what to do about them, please, read carefully the TIPS_NLP_Stanford CoreNLP memory issues.pdf.

If you are processing files in a directory, other files may similarly need to be split and the message display may become annoying.",Yes,No
whats_in_your_corpus,WordNet VERB aggregation,"CAVEAT!

For VERBS, the aggregated 'stative' category includes the auxiliary 'be' probably making up the vast majority of stative verbs. Similarly, the category 'possession' include the auxiliary 'have' (and 'get'). You may wish to exclude these auxiliary verbs from frequencies.

The WordNet_UP function will automatically compute VERB frequencies with/without auxiliaries and display both Excel charts.",Yes,No
whats_in_your_corpus,CoreNLP quote annotator,"The CoreNLP quote annotator works with double quotes as default "" rather than with single quotes '. If your document(s) use single quotes for dialogue, make sure to tick the checkbob 'Include single quotes'. The Stanford CoreNLP annotator will then process BOTH single AND double quotes, otherwise single quotes for dialogues would be missed (e.g., The user said: 'This NLP Suite sucks.').",Yes,No
GIS,GIS GUI options,"The options available on the GUI have been automatically set for you depending upon the type of input file selected: txt or csv.

With a TXT file, NER extraction via Stanford CoreNLP must be first performed.

With a CSV file, the script checks whether the file is a CoNLL table, a geocoded file containing latitude and longitude values, or a file containing a list of locations that need to be geocoded.",No,No
CoNLL_table_analyzer,CoNLL table - Verb modality,"The categories of Verb modality (Obligation, Will/would, Can/may) computed from the CoNLL table are NOT mutually exclusive. The same verb may appear in several categories.",Yes,No
NGrams_CoOccurrences_Viewer,subprocess.call(cmd) error,"subprocess.call(cmd) error

If the VIEWER you are running exits with an error code about a file not found, most likely your selected INPUT & OUTPUT directory options are too long for Windows to handle.

You may need to move your input and output folders so as to have a shorter path (e.g., desktop).",Yes,No
GIS,GIS default visualization options,"The Google Earth Pro visualization options in the GIS GUI are set by default. If you want to customize Google Earth Pro, please, use the GIS Google Earth GUI with the list of locations or of geocoded locations produced by the GIS pipeline as csv files.",Yes,No
NLP_default_IO,Input/Output options,"The two widgets for INPUT FILE and INPUT DIRECTORY are mutually exclusive. You can select one OR the other but not both. Click on either button to make your selection.

To change an already selected option from FILE to DIRECTORY or from DIRECTORY to FILE, simply click on the button you want to select, make your selection, and the I/O configuration will automatically update.",No,OFF
whats_in_your_corpus,What is in your corpus - Topic modeling,"The topic modeling option requires in input a set of txt documents, rather than a single txt file. The topic modeling option is disabled for single documents.",Yes,OFF
whats_in_your_corpus,CoreNLP exporting Json files,"Stanford CoreNLP can export in output Json files for the selected annotator(s)). Json files may give expert users checks against the NLP Suite performance about some CoreNLP annotators.

If you do not wish to produce these files, simply turn OFF this reminder by replying No to wanting to see this reminder again. And like for any reminder, you can always turn it back ON, and export Json files, at any time by using the 'Open reminders' dropdown menu at at the bottom of this GUI.",Yes,OFF
whats_in_your_corpus,NER tags frequency,"O is likely to be the most frequent NER tag in your corpus. It is likely to 'mask' all other tags. If that is the case, when the chart is displayed you may want to delete the row containing the O tag to have a better view of all other tags.",Yes,OFF
NLP_default_IO,Date options,"Some of the algorithms in the NLP Suite (e.g., GIS models and network models) can build dynamic models (i.e., models that vary with tiime) when time/date is known.

Tick the checkbox, if the filenames in the selected INPUT option embed a date (e.g., The New York Times_12-19-1899), the NLP Suite can use that metadata information to build dynamic models. If that is the case, using the dropdown menu, select the date format of the date embedded in the filename (default mm-dd-yyyy).

Please, enter the character used to separate the date field embedded in the filenames from the other fields (e.g., _ in the filename The New York Times_12-23-1992) (default _).

Please, using the dropdown menu, select the position of the date field in the filename (e.g., 2 in the filename The New York Times_12-23-1992; 4 in the filename The New York Times_1_3_12-23-1992 where perhaps fields 2 and 3 refer respectively to the page and column numbers) (default 2)",No,OFF
SVO,SVO output,"The SVO pipeline will create in output an SVO subdirectory inside the main output directory.

Depending upon the options you select it will also create different subdirectories (e.g., GIS, WordNet) inside the SVO subdirectory. Contrary to this, the creference resolution option will create a subdirectory inside the main output directory rather than the SVO subdirectory, since coreferenced files can then be used as input to any NLP algorithms.

Depending upon the options you select, the SVO pipeline will produce different types of files: cvf files, wordcloud image, Google Earth Pro map, and Gephi network graph.

While cvf and png files are easy to read, less so are Google Earth Pro kml files and, particularly, Gephi gexf files.

PLEASE, read the Gephi TIPS file before you run the SVO pipeline.",Yes,OFF
SVO,SVO default visualization options,"The SVO algorithms use default settings for visualizing results in Python Wordclouds and Google Earth Pro. If you want to customize the visualization options, please, use the Wordclouds GUI and the GIS Google Earth GUI with the csv files produced by SVO in input.",Yes,OFF
SVO,SVO with corpus data,"You have selected to work with a set of txt files in a directory (your corpus).

Beware that SVO extraction with Stanford CoreNLP is computationally demanding. Furthermore, depending upon the options you choose (manual coreference editing, GIS maps), it may require manual input on each input file processed.

Depending upon corpus size, manual coreference is also not possible, due to memory requirements.",Yes,OFF
NLP_default_IO,CoreNLP SVO timing,"Beware that the CoreNLP SVO algorithms on the 296 files (2042312 words total) of the President of the United States Inaugural and State of the Union speeches, takes approximately 1 hour and 20 minutes on a standard laptop.",Yes,OFF
wordclouds,NLP setup options,"Some of the algorithms behind this GUI rely on a specific NLP package to carry out basic NLP functions (e.g., sentence splitting, tokenizing, lemmatizing) for a specific language your corpus is written in.

Your selected corpus language is English.
Your selected NLP package for basic functions (e.g., sentence splitting, tokenizing, lemmatizing) is Stanza.

You can always view your default selection saved in the config file NLP_default_package_language_config.csv by hovering over the Setup widget at the bottom of this GUI and change your default options by selecting Setup NLP package and corpus language.",No,ON
NLP_default_IO,spaCy annotators,"Contrary to Stanford CoreNLP and Stanza, spaCy does not process specific annotators (e.g., POS, NER). Regardless of selected annotator, spaCy will also process the corpus with its full parser.",Yes,OFF
NLP_default_IO,WordNet VERB aggregation,"CAVEAT!

For VERBS, the aggregated 'stative' category includes the auxiliary 'be' probably making up the vast majority of stative verbs. Similarly, the category 'possession' include the auxiliary 'have' (and 'get'). You may wish to exclude these auxiliary verbs from frequencies.

The WordNet_UP function will automatically compute VERB frequencies with/without auxiliaries and display both Excel charts.",Yes,OFF
NLP_default_IO,SVO Someone?,"The SVO algorithms convert passive sentences into active ones. When no subject is present (e.g., ""A beautiful car was bought""), a subject is automatically added as Someone?.",Yes,OFF
NLP_default_IO,Output directory of split files,"This is a reminder that all file splitter scripts save the split files inside a subdirectory by the name of split_files of the directory where the input txt files are located, regardless of the choice of output directory.",Yes,OFF
NLP_default_IO,% sign in file,"The file contains % sign. This will break Stanford CoreNLP annotators. The % sign was temporarily replaced with ""percent"" for processing. But... you should run the script ""Convert non-ASCII apostrophes & quotes and % to percent"" to change the sign permanently.",Yes,OFF
file_search_byWord,NLP setup options,"Some of the algorithms behind this GUI rely on a specific NLP package to carry out basic NLP functions (e.g., sentence splitting, tokenizing, lemmatizing) for a specific language your corpus is written in.

Your selected corpus language is English.
Your selected NLP package for basic functions (e.g., sentence splitting, tokenizing, lemmatizing) is Stanza.

You can always view your default selection saved in the config file NLP_default_package_language_config.csv by hovering over the Setup widget at the bottom of this GUI and change your default options by selecting Setup NLP package and corpus language.",No,OFF
